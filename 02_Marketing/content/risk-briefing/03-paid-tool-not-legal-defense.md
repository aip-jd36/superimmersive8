# Why "I paid for the tool" isn't a legal defense

**Last Updated:** February 2026

**TL;DR:** Paying for Runway Pro or Midjourney doesn't mean you own safe, defensible content. Courts are increasingly ruling that AI outputs are *not* copyrightable unless there's significant human authorship — and even then, the training data itself may be infringing.

---

## The Myth: "I Paid for It, So I Own It"

This is the most dangerous assumption brands make about AI-generated content:

> *"We paid for Runway's commercial plan. That means we can use the outputs however we want, right?"*

**Wrong.** Here's what you actually own:

✅ **A license to use the tool's outputs commercially** (per the ToS)
❌ **NOT copyright protection** if the output is too similar to training data
❌ **NOT indemnification** if someone sues you for infringement
❌ **NOT proof** the training data was legally obtained

---

## What the U.S. Copyright Office Actually Said

**May 2025:** The U.S. Copyright Office released updated guidance on AI-generated works:

> *"Works generated entirely by AI without meaningful human creative control are not eligible for copyright protection."*

**What this means:**
- If you typed a prompt into Runway and clicked "generate," the output is *not copyrightable by you*.
- If you edited, selected, iterated, and directed the AI output significantly, *you may* have copyright — but only over your contributions, not the AI's.
- If the AI's output closely resembles its training data (e.g., copyrighted films), you could be liable for infringement *even if you didn't know*.

---

## The "Transformativeness" Rejection

**August 2024:** A U.S. District Court ruled in *Getty Images v. Stability AI* that AI outputs trained on copyrighted images *are not transformative* simply because they're AI-generated.

**Translation:** The fact that an AI tool generated it doesn't make it a new, legally distinct work. If the output is substantially similar to copyrighted training data, it's still infringement.

**The precedent:** Stability AI's defense was: *"We trained on publicly available images, and our outputs are new works."*
**The court's response:** *"Doesn't matter. If your model can reproduce copyrighted elements without permission, that's infringement."*

This ruling applies to **all generative AI tools** — Midjourney, Runway, Pika, Sora, Kling. If the model was trained on copyrighted data without licensing, outputs that resemble that data are at risk.

---

## The Vicarious Liability Problem

**Canada, 2023:** Air Canada's chatbot gave a customer incorrect refund information. The customer sued. Air Canada's defense: *"The chatbot made a mistake — we're not responsible."*

**The court's ruling:** *"The chatbot represents your company. You are liable for its outputs."*

**How this applies to AI video:**
- If you use AI-generated content in a campaign, **you are responsible** for what's in that content.
- If the AI generated a scene that infringes on someone's copyright (e.g., a character that looks like Mickey Mouse), **you are liable**, not Runway.
- Saying *"the AI made it"* is not a defense.

---

## What About Fair Use?

Brands often ask: *"Can't we claim fair use?"*

**No.** Fair use is a narrow exception, and it almost never applies to commercial advertising or branded content. Here's why:

**Fair use requires:**
1. Transformative purpose (commentary, criticism, education)
2. Non-commercial use (or minimal commercial impact)
3. Limited amount used
4. No market harm to the original work

**Branded AI video fails on all counts:**
- ❌ Purpose: Commercial (selling a product/service)
- ❌ Nature: Entirely commercial
- ❌ Amount: Often reproduces visual styles wholesale
- ❌ Market harm: Competes with licensed content

**Bottom line:** If you're making money from it, it's not fair use.

---

## What Actually Protects You

Paying for the tool is step one. But legal defensibility requires:

1. **Human authorship documentation** — proof you directed, iterated, selected, and edited the AI output (not just one-click generation)
2. **Tool tier assessment** — Adobe Firefly = indemnified. Runway/Pika/Sora = not indemnified but high-quality if vetted.
3. **Rights Verified vetting** — IP imitation review, likeness rights check, brand safety clearance
4. **Chain of Title documentation** — tool provenance log, commercial use authorization, SHA-256 file hash, platform compliance checklist

**SI8's model:** Every catalog production includes all four. For Tier 2 placements, brand elements are AI-regenerated into existing vetted productions — so you get the creative quality of Runway/Sora with documented defensibility.

---

## Questions?

**Book a 20-Minute AI Video Risk Triage Call** — bring your campaign concept or production sample, and we'll flag risks and recommend next steps.

[Book Your Risk Triage Call](https://calendly.com/superimmersive8)

Or **sign up for our monthly newsletter** — we track legal cases, platform updates, and Copyright Office rulings so you don't have to.

[Get Monthly Risk Briefings](https://superimmersive8.com#email-signup)
