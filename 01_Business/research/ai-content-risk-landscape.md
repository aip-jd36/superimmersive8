# AI Content Risk Landscape — Research Brief

**Compiled:** February 2026
**Purpose:** Source material for SI8 marketing copy, blog posts, email campaigns, and sales conversations
**Primary audience this content serves:** Brand marketing directors, agency creative leads, brand legal/compliance teams

---

## THE CORE ARGUMENT THIS RESEARCH SUPPORTS

"Won't get you sued" is not a tagline. It describes a real, documented, accelerating legal environment that most brands are not prepared for. The risk comes from three directions simultaneously: the tools themselves are in litigation, the legal environment is accelerating faster than anyone expected, and the tool providers' indemnity doesn't cover brands the way they assume it does.

---

## SECTION 1: THE TOOLS THEMSELVES ARE IN COURT

### Midjourney: Three major studios, $300M+ in claimed damages

**June 11, 2025:** Disney, NBCUniversal, and DreamWorks sued Midjourney for copyright infringement, calling it "theft" and showing examples of the tool generating recognizable copyrighted characters — Yoda, Bart Simpson, Iron Man, Shrek — without being explicitly prompted to.

**September 4, 2025:** Warner Bros. Discovery filed a separate lawsuit against Midjourney. Damages claim: $300 million. Allegation: "systematic and willful" infringement.

Three of Hollywood's five major studios have now sued Midjourney. The cases are ongoing.

**Midjourney's defense — and why it matters for brands:** Midjourney is arguing that *users* are responsible for prompting infringing outputs, not Midjourney. If this argument succeeds, liability migrates from the tool to the brand or agency that used it commercially. A brand that ran a campaign using Midjourney-generated content could find itself in the liability chain.

Sources:
- [Disney, Universal File First Major Studio Lawsuit Against Midjourney (Variety, June 2025)](https://variety.com/2025/digital/news/disney-nbcuniversal-studio-lawsuit-ai-midjourney-copyright-infringement-1236428188/)
- [Warner Bros. Complaint: 'Systematic, Willful' Infringement (IPWatchdog, September 2025)](https://ipwatchdog.com/2025/09/08/warner-bros-complaint-alleges-midjourneys-copyright-infringement-systematic-willful/)

---

### Runway: Trained on stolen content, no indemnity for users

**July 2024:** Leaked internal documents showed that Runway's Gen-3 model was trained using thousands of YouTube videos downloaded without permission — including content owned by Disney, Netflix, Pixar, Sony, and The New Yorker. Runway reportedly used proxy software specifically to avoid being detected and blocked by YouTube during the scraping process.

Runway is also a named defendant in the Andersen v. Stability AI class action (Northern District of California), along with Stability AI, Midjourney, and DeviantArt.

**Runway's user terms:** Runway requires users to indemnify Runway against losses related to copyright infringement. The indemnity runs *from user to Runway*, not the other way. Runway provides no contractual protection to commercial users.

Sources:
- [Runway Trained on Stolen YouTube Content — Including Disney, Netflix, Pixar (Futurism, July 2024)](https://futurism.com/leak-runway-ai-video-training)
- [Runway Faces Backlash After Unauthorized Training Report (VentureBeat, July 2024)](https://venturebeat.com/ai/runway-faces-backlash-after-report-of-copying-ai-video-training-data-from-youtube)

---

### Suno: Settled with major labels and retired its model

**June 2024:** The RIAA filed copyright infringement suits against Suno (Boston) and Udio (New York) on behalf of Sony Music, UMG Recordings, and Warner Records. Statutory damages sought: up to $150,000 per infringing song.

**2025 settlements:** Warner Music Group settled with Suno. The settlement terms included Suno's commitment to retire its current AI music model and launch "new, advanced and licensed models" in 2026.

Translation: the model that produced Suno's existing outputs was indefensible enough that the company agreed to phase it out. Any brand with Suno-generated audio in active commercial content is now using music from a model that was retired as part of a copyright settlement.

Sources:
- [Record Companies File Landmark Cases Against Suno and Udio (RIAA, June 2024)](https://www.riaa.com/record-companies-bring-landmark-cases-for-responsible-ai-againstsuno-and-udio-in-boston-and-new-york-federal-courts-respectively/)
- [Why the Suno Lawsuit Matters for the Music Tech Ecosystem (Level Law)](https://level.law/news/why-the-suno-lawsuit-matters-for-the-music-tech-ecosystem)

---

### Getty Images v. Stability AI: Watermarks in outputs

The UK High Court's November 2025 ruling found that Getty/iStock watermarks appearing in Stable Diffusion outputs constituted trademark infringement. The practical implication: if AI-generated images contain degraded Getty watermarks — a documented phenomenon with Stable Diffusion — any commercial use of those images is provably problematic.

Sources:
- [Getty v. Stability AI: Most Important AI Legal Decision to Date (William Fry, November 2025)](https://www.williamfry.com/knowledge/getty-images-v-stability-ai-the-most-important-ai-legal-decision-to-date/)

---

### The velocity stat: 70+ active cases by end-2025, doubled in one year

From approximately 30 active copyright infringement cases against AI companies at end-2024 to over 70 by late 2025. This is not a legal trend that is stabilizing. It is accelerating.

Source:
- [AI's War in the Courtroom: Copyright Disputes Spike in 2025 (Best Law Firms)](https://www.bestlawfirms.com/articles/ai-war-in-the-courtroom-copyright-disputes-spike-in-2025/7186)

---

## SECTION 2: THE LEGAL ENVIRONMENT IS ACCELERATING

### The "paid for the tool" argument is not a complete defense

**U.S. Copyright Office Report, May 9, 2025:** The Copyright Office's formal AI and copyright report explicitly states that using copyright-protected materials for AI model training is insufficient to justify fair use. Critically, the *knowing* use of illegally obtained training data weighs against fair use defense — meaning if a tool was trained on stolen content (as the Runway leak suggests), users of that tool are relying on a compromised legal foundation.

**2025 court ruling:** A U.S. court rejected the transformativeness argument for commercial AI outputs, finding that transformation does not occur simply because copyrighted content does not appear verbatim in the output. This dismantles the most common assumption brands make: "it's generated content, it's not a copy, we're fine."

The commercial license from the tool company cannot grant rights the tool company didn't have. Two separate legal relationships. One does not cover the other.

Sources:
- [Copyright Office Weighs In on AI Training and Fair Use (Skadden, May 2025)](https://www.skadden.com/insights/publications/2025/05/copyright-office-report)
- [Court Rules AI Training on Copyrighted Works Is Not Fair Use (Davis+Gilbert)](https://www.dglaw.com/court-rules-ai-training-on-copyrighted-works-is-not-fair-use-what-it-means-for-generative-ai/)

---

### Right of publicity: The Scarlett Johansson precedent and what it means for brands

**May 2024:** OpenAI released a ChatGPT voice called "Sky" that was "uncannily similar" to Scarlett Johansson's voice after she had twice declined to license her voice to OpenAI. She retained legal counsel; OpenAI withdrew the voice.

The governing legal precedent: *Midler v. Ford* (1988). Ford hired a soundalike to imitate Bette Midler's voice in a commercial after Midler declined. The Ninth Circuit found Ford liable — not for using Midler's recordings, but for the deliberate imitation. AI-generated voices that resemble real people trigger the same right-of-publicity exposure.

**State legislation:** Tennessee ELVIS Act (2024), California AB 2602 (2024 — deceased performers), New York Synthetic Performer Disclosure Law (December 2025), federal NO FAKES Act (introduced in both chambers). The legislative trend is unmistakable: every state is moving toward greater protection, not less.

Sources:
- [Scarlett Johansson Takes Legal Action Over Unauthorized ChatGPT Voice (Boston Brand Media)](https://www.bostonbrandmedia.com/news/scarlett-johansson-takes-legal-action-over-unauthorized-chatgpt-voice-mimicry-that-shocked-and-angered-her)
- [Synthetic Media & Right of Publicity Risk Map for 2026 (Holon Law)](https://holonlaw.com/entertainment-law/synthetic-media-voice-cloning-and-the-new-right-of-publicity-risk-map-for-2026/)

---

### Regulatory hard deadlines

| Deadline | Jurisdiction | Requirement |
|----------|-------------|------------|
| **January 2026** | South Korea | Framework Act on AI — mandatory AI labeling for certain applications |
| **June 2026** | New York (US) | Synthetic Performer Disclosure Law — conspicuous disclosure when AI-generated talent appears in any advertising. Civil penalties: $1,000 first violation, $5,000 subsequent. |
| **August 2026** | European Union | EU AI Act Article 50 — AI-generated video/audio must be clearly identifiable as artificial. Machine-readable watermarks or metadata required. |
| December 2025 (passed) | Taiwan | AI Basic Act — training on others' copyrighted work requires license or fair use; AI-generated outputs resembling protected works may themselves infringe. |

**The pace problem:** 1,100+ AI-related bills were introduced in U.S. state legislatures in 2025 alone. Approximately 100 were enacted or proposed into final rules. The regulatory load is not a one-time event — it is a continuous expansion.

Sources:
- [AI Disclosure Requirements: Navigating State Laws and Platform Rules (AdExchanger/Davis+Gilbert)](https://www.adexchanger.com/data-driven-thinking/ai-disclosure-requirements-navigating-state-laws-and-platform-rules/)
- [Taiwan Legislature Passes New AI Law (Taipei Times, December 2025)](https://www.taipeitimes.com/News/front/archives/2025/12/24/2003849407)
- [South Korea's New AI Framework Act (Future of Privacy Forum)](https://fpf.org/blog/south-koreas-new-ai-framework-act-a-balancing-act-between-innovation-and-regulation/)
- [EU AI Act Article 50 (artificialintelligenceact.eu)](https://artificialintelligenceact.eu/article/50/)

---

## SECTION 3: THE INDEMNIFICATION TABLE — WHAT YOUR TOOL ACTUALLY COVERS

This is the clearest version of the "paid for the tool" gap:

| Tool | Enterprise indemnification for commercial users? |
|------|------------------------------------------------|
| Adobe Firefly (Enterprise) | **Yes** — Adobe assumes legal/financial liability if enterprise customer is sued for copyright infringement based on Firefly output |
| Microsoft Copilot (Enterprise) | **Yes** |
| OpenAI (Enterprise tier) | **Yes** (partial — subject to conditions) |
| **Runway** | **No** — indemnity runs *from user to Runway*, not the reverse |
| **Midjourney** | **No** — explicitly disclaims IP warranties; outputs "as is" without non-infringement promises |
| **Kling (Kuaishou)** | **No** enterprise indemnification confirmed |

**Adobe's moat — and its ceiling:** Adobe Firefly is trained exclusively on Adobe Stock and public domain/licensed content. Enterprise customers have real contractual protection. The trade-off: Firefly's outputs are, by professional AI standards, generic. The creative range of Runway, Sora, Kling, and Midjourney is categorically different.

**The gap SI8 fills:** Brands want Runway/Sora/Kling creative quality. They don't want to hold the legal exposure unaccompanied. SI8 provides the documented vetting process that bridges the gap between creative capability and commercial defensibility.

Sources:
- [MidJourney, Warner Bros. and AI Indemnity (Aragon Research)](https://aragonresearch.com/midjourney-warner-bros-and-ai-indemnity/)
- [Can I Use Runway ML Videos Commercially? (Terms.Law)](https://terms.law/forum/thread/runway-ml-video-commercial-rights.html)
- [Adobe's Legally Grounded AI Model (EDRM, July 2025)](https://edrm.net/2025/07/adobes-legally-grounded-ai-model-offers-a-blueprint-for-responsible-innovation/)

---

## SECTION 4: THE PLATFORM COMPLIANCE NIGHTMARE

Four major platforms. Four structurally different requirements. One piece of content, four compliance problems.

### YouTube (2025 rules)

**March 2024:** Mandatory AI disclosure toggle for "realistic altered or synthetic content." Triggers: synthetic/cloned voices resembling real people, digitally manipulated visuals of real people, fabricated real-world events.

**July 15, 2025 escalation:** YouTube added a second enforcement layer — mass-produced or fully AI-generated content without "significant human creativity and editorial judgment" is now demonetized *regardless* of disclosure. A channel, True Crime Case Files (83,000+ subscribers), was removed entirely after 150+ videos were flagged.

**Penalties:** Content strikes → demonetization of individual videos → removal from YouTube Partner Program → channel termination for repeat violations.

Sources:
- [YouTube's AI Disclosure Requirements: The Complete 2025 Guide (Onewrk)](https://onewrk.com/youtubes-ai-disclosure-requirements-the-complete-2025-guide/)
- [YouTube Monetization Update: AI Content Demonetized from July 15](https://myelectricsparks.com/youtube-monetization-policy-update-2025-mass-produced-ai-content-demonetized/)

---

### TikTok

**Requirement:** Manual disclosure for content imported from third-party AI tools (Runway, Kling, Sora). TikTok auto-labels its own in-app AI content but does not reliably auto-detect third-party AI. The uploader is responsible either way.

**Brand advertising specific:** Commercial/promotional content must use TikTok's built-in disclosure tools. Missing disclosure = removal from For You feed = direct impact on ad performance and campaign ROI.

**Scale of enforcement:** Over 51,000 synthetic media videos removed in a single six-month enforcement period.

Source:
- [New Labels for Disclosing AI-Generated Content (TikTok Newsroom)](https://newsroom.tiktok.com/en-us/new-labels-for-disclosing-ai-generated-content)

---

### Meta / Instagram / Facebook

**May 2024:** C2PA-based auto-labeling deployed across Instagram, Facebook, and Threads. Over 330 million pieces labeled. 1 trillion+ user views of the "AI Info" label in October 2024 alone.

**The false positive problem — directly relevant to brands:** Legitimate product photography is being auto-labeled "AI Info" because it was exported from Adobe Photoshop with residual C2PA metadata — even when AI was only used for minor retouching, not generation. Meta recommends stripping metadata before upload using ExifTool or "Save for Web" export. The compliance burden has shifted to the brand's production workflow.

If a brand's AI-generated ad content is labeled automatically without a brand disclosure accompanying it, the appearance is that the brand was trying to conceal AI use — which creates FTC and reputational risk simultaneously.

Sources:
- [Our Approach to Labeling AI-Generated Content (Meta)](https://about.fb.com/news/2024/04/metas-approach-to-labeling-ai-generated-content-and-manipulated-media/)
- [Labeling AI Content (Meta Transparency Center)](https://transparency.meta.com/governance/tracking-impact/labeling-ai-content)

---

### Netflix (Streaming / Licensed Programming)

**August 2025:** Netflix published the first formal Generative AI Production Guidelines from a major streaming platform. These apply to all production partners and licensed content.

**Key requirements:**
- Proactive disclosure of intended AI use to Netflix contact *before production begins*
- Written pre-approval required if AI outputs will appear in final deliverables, involve talent likeness, third-party IP, or union-covered performances
- Tools that store, reuse, or train on production data: prohibited
- AI cannot replace or generate new talent performances without consent

**For brands:** Any brand-sponsored content or product placement in Netflix productions must pass this framework. Content with undisclosed AI use is potentially unlicensable or must be redisclosed retroactively.

Sources:
- [Using Generative AI in Content Production (Netflix Partner Help Center)](https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production)
- [Netflix Publishes Generative AI Guidelines (CineD, August 2025)](https://www.cined.com/netflix-publishes-generative-ai-guidelines-for-content-production/)

---

### The cross-platform conflict

**YouTube:** Upload toggle disclosure
**TikTok:** Manual caption/in-video disclosure; in-platform disclosure tools for ads
**Meta:** C2PA metadata auto-detection; brand responsibility to strip or confirm metadata
**Netflix:** Pre-production written approval with documented AI use log

These are four structurally different mechanisms for one piece of content. A brand running a campaign across all four must track and comply with four separate, independently-updated regimes. No single workflow covers all of them. The IAB launched a quarterly Video Compliance Brief series in 2025 specifically because the complexity has become unmanageable without dedicated tracking.

**The additional state-law layer:** 1,100+ AI bills introduced in 2025. The current US regulatory landscape is described by legal analysts as "a free-for-all" with some states having very conservative disclosure requirements and others having none — with overlapping and often conflicting obligations for brands operating nationally.

Sources:
- [IAB Video Compliance Brief: AI Transparency (IAB, December 2025)](https://www.iab.com/guidelines/video-compliance-brief-december-2025/)
- [AI Disclosure Requirements: Navigating State Laws and Platform Rules (AdExchanger)](https://www.adexchanger.com/data-driven-thinking/ai-disclosure-requirements-navigating-state-laws-and-platform-rules/)

---

## SECTION 5: VICARIOUS LIABILITY — THE BRAND IS NOT INSULATED BY THE AGENCY

Standard agency contracts currently do not contain AI-specific IP representations, warranties, or indemnification provisions. Law firms advising brand owners are now recommending that brands amend agency contracts specifically to add provisions guarding against copyright infringement from agency AI use.

Under vicarious liability principles, a brand that commissioned AI-generated content and profited from it can be held liable even if the agency was the direct infringer. "We hired the agency, we didn't know what tools they used" is not a complete defense.

**The Air Canada chatbot precedent (2024):** Courts held Air Canada liable for false information provided by its chatbot, finding that disclaimers cannot shift legal responsibility to users. This principle applies to any AI-generated content a brand publishes or distributes — the brand cannot disclaim its way out of responsibility for what it puts in market.

Sources:
- [Advertising Law Alert: How Brands Can Identify and Mitigate AI-Related Risks (Davis+Gilbert/Lexology)](https://www.lexology.com/library/detail.aspx?g=7f5a0d72-edb7-4575-9407-ac60344b81b9)
- [Generative AI and Copyright Infringement: What Brands Need to Know (BrandShield)](https://www.brandshield.com/blog/generative-ai-and-copyright-infringement-what-brands-need-to-know/)

---

## MARKETING ANGLES: HOW TO DEPLOY THIS RESEARCH

### For cold email / short-form outreach (open with one specific fact)

Most effective openers, in order:
1. **The indemnification table** — "Runway covers you for zero if you're sued. Here's the full breakdown."
2. **Suno retired its model** — "The AI music tool in your campaigns retired its own model because of copyright litigation. Here's what that means for content you've already shipped."
3. **Runway's training data leak** — "Runway's video model was trained on YouTube content scraped from Disney, Netflix, and Pixar without permission. Your commercial team needs to know this."

### For a blog post / longer-form content

Three-act structure:
1. The tools are being sued (specific cases, specific facts)
2. Your tool provider doesn't cover you (indemnification table)
3. The compliance nightmare is real and getting worse (platform patchwork + regulatory acceleration)

### For the sales conversation / proposal stage

Use the platform complexity section. Marketing ops people feel this viscerally. "Here are four platforms you run content on. Here are their four different, contradictory disclosure requirements. Here's what happens to you if you get any one of them wrong."

### For the website / positioning copy

Lead with the regulatory deadline table. June 2026 (New York) and August 2026 (EU AI Act) are hard deadlines with real penalties. They're far enough away that brands aren't panicking yet, but close enough that "we should get ahead of this" is a compelling frame.

---

## WHAT SI8 CAN AND CANNOT CLAIM

**Can claim:**
- SI8's Rights Verified process documents tool provenance, commercial license status, and human authorship in a structured Chain of Title
- The Chain of Title provides a documented chain of defensibility that brands can present to buyers, platforms, and legal teams
- SI8 reviews against a defined criteria set including likeness, IP imitation, brand safety, and modification rights
- SI8-vetted content from Runway/Kling/Sora comes with documentation that Adobe Firefly content automatically carries, but that unvetted non-Adobe AI content lacks

**Cannot claim:**
- That SI8 guarantees non-infringement (we do not)
- That SI8's process is a legal certification (it is not)
- That SI8 provides legal advice (we do not)
- That content in SI8's catalog is "rights-cleared" — use "safe lane vetted" or "through our safe lane process"

---

*Research compiled February 2026. Sources are current as of date of compilation. AI legal landscape is actively evolving — verify specific case statuses before using in formal legal or compliance contexts.*
